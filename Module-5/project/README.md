
# Module 5 Final Project

## Project Summary

Congratulations! You've made it through another _intense_ module, and now you're ready to show off your newfound Machine Learning skills!

![awesome](images/smart.gif)

All that remains for Module 5 is to complete the final project and an assessment!

## The Project

For this project, you're going to select a dataset of your choosing and create classification models. You'll start by identifying a problem you can solve with classification, and then identify a dataset. You'll then use everything you've learned about Data Science and Machine Learning thus far to source a dataset, preprocess and explore it, and then build and interpret a classification model that answers your chosen question.


### Selecting a Data Set

We encourage you to be very thoughtful when identifying your problem and selecting your data set--an overscoped project goal or a poor data set can quickly bring an otherwise promising project to a grinding halt.

To help you select an appropriate data set for this project, we've set some guidelines:

1. Your dataset should work for classification. The classification task can be either binary or multiclass, as long as it's a classification model.   

2. Your dataset needs to be of sufficient complexity. Try to avoid picking an overly simple dataset. Try to avoid extremely small datasets, as well as the most common datasets like titanic, iris, MNIST, etc. We want to see all the steps of the Data Science Process in this project--it's okay if the dataset is mostly clean, but we expect to see some preprocessing and exploration. See the following section, **_Data Set Constraints_**, for more information on this.   

3. On the other end of the spectrum, don't pick a problem that's too complex, either. Stick to problems that you have a clear idea of how you can use machine learning to solve it. For now, we recommend you stay away from overly complex problems in the domains of Natural Language Processing or Computer Vision--although those domains make use of Supervised Learning, they come with a lot of other special requirements and techniques that you don't know yet (but you'll learn soon!). If you're chosen problem feels like you've overscoped, then it probably is. If you aren't sure if your problem scope is appropriate, your coaches will  flag it to you by Friday!  

4. **_Serious Bonus Points_** if some or all of the data is data you have to source yourself through web scraping or interacting with a 3rd party API! Having projects that show off your ability to source data effectively make you look that much more impressive when showing your work off to potential employers!

### Data Set Constraints

When selecting a data set, be sure to take into consideration the following constraints:

1. Your data set can't be one we've already worked with in any labs.
2. Your data set should contain a minimum of 1000 rows.    
3. Your data set should contain a minimum of 10 predictor columns, before any one-hot encoding is performed.   
4. Your instructors must provide final approval on your data set.

### Problem First, or Data First?

There are two ways that you can about getting started: **_Problem-First_** or **_Data-First_**.

**_Problem-First_**: Start with a problem that you want to solve with classification, and then try to find the data you need to solve it.  If you can't find any data to solve your problem, then you should pick another problem.

**_Data-First_**: Take a look at some of the most popular internet repositories of cool data sets we've listed below. If you find a data set that's particularly interesting for you, then it's totally okay to build your problem around that data set.

There are plenty of amazing places that you can get your data from. We recommend you start looking at data sets in some of these resources first:

* [UCI Machine Learning Datasets Repository](https://archive.ics.uci.edu/ml/datasets.html)
* [Kaggle Datasets](https://www.kaggle.com/datasets)
* [Awesome Datasets Repo on Github](https://github.com/awesomedata/awesome-public-datasets)
* [New York City Open Data Portal](https://opendata.cityofnewyork.us/)
* [Inside AirBNB ](http://insideairbnb.com/)
* [Google Dataset Search Engine](https://toolbox.google.com/datasetsearch)


## The Deliverables

For online students, your completed project should contain the following four deliverables:

1. A **_Technical Jupyter Notebook_** containing any code you've written for this project. This work will need to be pushed to your GitHub repository in order to submit your project.  This notebook is clean and narrative. Extra data cleaning functions and additional EDA should be done in separate notebooks or, preferably, in separate .py files.

2. An organized **README.md** file in the GitHub repository that describes the nature and contents of the repository. This file should be the source of information for navigating through the repository. 

4. An **_"Executive Summary" PowerPoint Presentation_** that gives a brief overview of your problem & dataset and shows the different models you've generated trying to solve the problem.  The emphasis should be on showcasing your model evaluation and how you determined which model performs best.
  
For those who wish to showcase more info, extra slides showcasing technical information may be included, but should not be expected to be seen unless specific questions come up about those topics.  The presentation is strictly non-technical (from a programming perspective).

### Jupyter Notebook Must-Haves

For this project, your Jupyter Notebook should meet the following specifications:

**_Organization/Code Cleanliness_**

* The notebook should be well organized, easy to follow, and code is commented where appropriate.  
    * Level Up: The notebook contains well-formatted, professional looking markdown cells explaining any substantial code. All functions have docstrings that act as professional-quality documentation.  
* The notebook is written to technical audiences with a way to both understand your approach and reproduce your results. The target audience for this deliverable is other data scientists looking to validate your findings.  

**_Process, Methodology, and Findings_**

* Your notebook should contain a clear record of your process and methodology for exploring and preprocessing your data, building and tuning a model, and interpreting your results.

## Grading Rubric 

A generic grading rubric for the project can be found [here](https://github.com/learn-co-curriculum/dsc-mod-5-project/blob/master/module5_project_rubric.pdf), though this is more a guideline than a strict rubric.

## Timeline
### Day -3 (Wednesday):
Project kick-off.  Be thinking of problems and/or datasets you'd like to tackle

### Day -2 (Thursday):
Project idea submissions.  Please be prepared to submit 1-2 ideas to the instructional staff by 11am. We will provide feedback if we think the scopes of your proposals are too narrow or too wide.

_Contents_:
Problem statement
The models you plan to employ
Data source, description, any preprocessing you think is required
Model evaluation measures
Real-world insights

This will be collected via Google Form.

### Day -1 (Friday):
Project groupings announced.  Meet with your partner and agree on a problem and dataset(s) to use. You may want to use the weekend to gather all the data you need to hit the ground running on Day 1.

### Day 1 (Monday):
Coach check-ins in the afternoon. Be prepared to talk about your data, your problem, and your baseline model.

### Day 2 (Tuesday):
Check-ins with your lead instructor in the afternoon.  Be prepared to talk about your models' performances and how you plan to select a final model. An outline of your final presentation is also expected.

### Day 3 (Wednesday):
Project presentations. As before, the final presentation should be for a smart but non-technical audience, and should be no more than 5 minutes in length. Bonus technical slides are fine, but should not be a part of the 5 minutes.
